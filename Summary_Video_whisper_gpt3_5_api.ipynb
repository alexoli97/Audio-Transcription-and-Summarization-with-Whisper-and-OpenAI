{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Transcription and Summarization with Whisper and OpenAI\n",
        "\n",
        "## Description\n",
        "This program is a tool for automatically transcribing and summarizing the content of audio and video files. It uses Whisper's voice recognition technology for transcription and OpenAI's API for generating summaries. It is designed to be run in a Google Colab environment.\n",
        "\n",
        "## Features\n",
        "- **Audio/Video Transcription**: Uses the Whisper model to transcribe audio extracted from video files.\n",
        "- **Automatic Language Detection**: Ability to detect the language of the audio for accurate transcription.\n",
        "- **Summary Generation**: Uses the OpenAI API to summarize the transcribed text, ideal for meetings, conferences, etc.\n",
        "\n",
        "## Use of the OpenAI API\n",
        "This program makes use of the OpenAI API, which is a paid service. Please **use this API responsibly** to avoid excessive charges.\n",
        "\n",
        "## GPU Configuration\n",
        "It's crucial to ensure that you are using a GPU in Google Colab for optimal performance. To activate the GPU:\n",
        "   - Go to `Runtime` > `Change runtime type`.\n",
        "   - Select `T4 GPU` in the hardware accelerator option.\n",
        "   - Save and proceed to run the notebook.\n",
        "\n",
        "## Usage Instructions\n",
        "1. **Video Upload**: Upload your video file to the Colab environment.\n",
        "2. **Video Configuration**: Update the path in the script to match the location of your uploaded video.\n",
        "3. **API Configuration**: Verify that the OpenAI API key is correctly configured in the environment.\n",
        "4. **Script Execution**: Go to `Runtime` > `Run all`.\n",
        "5. **Access to Results**: The transcribed and summarized texts will automatically be saved in text files within the Colab environment.\n",
        "\n",
        "## Dependencies\n",
        "- **Whisper**: Advanced voice recognition.\n",
        "- **moviepy**: Video editing and processing.\n",
        "- **ffmpeg**: Conversion and manipulation of multimedia files.\n",
        "- **tiktoken**: Authentication token management.\n",
        "- **openai**: Interface for OpenAI language models (GPT-3-5 in this case).\n",
        "\n",
        "## Authors and Acknowledgments\n",
        "This script has been developed by Alejandro Oliveros Ordás with the help of OpenAI and Whisper technologies.\n"
      ],
      "metadata": {
        "id": "FWUAR0jmqfUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = #your api key\n",
        "\n",
        "video_path = #your video path"
      ],
      "metadata": {
        "id": "bsyWqI_9ivoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available for GPU use\n",
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re8_1glpwk-N",
        "outputId": "923b50ac-f446-4784-a1a3-e014d11de4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi9E4zHi1foa",
        "outputId": "d62a6530-987f-4f62-9674-0d6546000e62",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-o46h1hkh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-o46h1hkh\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=e878f0edec8c072ef02dc416f9af4ea7c31314510f1a493d8297126a8841d115\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8mwt3s4y/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20231117\n",
            "    Uninstalling openai-whisper-20231117:\n",
            "      Successfully uninstalled openai-whisper-20231117\n",
            "Successfully installed openai-whisper-20231117\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Collecting tiktoken\n",
            "  Using cached tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "Collecting openai\n",
            "  Using cached openai-1.5.0-py3-none-any.whl (223 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.5.0\n"
          ]
        }
      ],
      "source": [
        "# @title Installing Dependencies\n",
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n",
        "!pip install moviepy\n",
        "!apt install ffmpeg\n",
        "!pip install tiktoken\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5qZjzEA1fod",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import Dependencies\n",
        "import whisper\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import io\n",
        "import requests\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL7Omun11foe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d5bb74-84d8-4233-ff43-fe4ac98e5702",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 100MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 762,321,920 parameters.\n"
          ]
        }
      ],
      "source": [
        "# @title Load the Whisper model\n",
        "\n",
        "# Cargar el modelo de Whisper\n",
        "model = whisper.load_model(\"medium\", device=DEVICE)\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload video and extract audio\n",
        "# Cargar el video y extraer el audio usando ffmpeg\n",
        "extracted_audio_path = '/content/extracted_audio.mp3'  # Ruta para el archivo de audio extraído\n",
        "command = ['ffmpeg', '-i', video_path, '-f', 'mp3', extracted_audio_path]\n",
        "subprocess.run(command)"
      ],
      "metadata": {
        "id": "r_zI7fuhUKcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4069ec-8c59-4857-ce82-3041b46d2427",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['ffmpeg', '-i', '/content/drive/MyDrive/MyBS/wf_rotado_no_va.mkv', '-f', 'mp3', '/content/extracted_audio.mp3'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Process audio and detect language\n",
        "\n",
        "# Procesar el audio\n",
        "audio = whisper.load_audio(extracted_audio_path)\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# Detectar el idioma del audio\n",
        "_, probs = model.detect_language(mel)\n",
        "detected_language = max(probs, key=probs.get)\n",
        "print(f\"Detected language: {detected_language}\")"
      ],
      "metadata": {
        "id": "43WwzFLFWj2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "605d2a2b-bbaa-4ade-ebfd-9a65a0d48b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: es\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDKhk1xR1fof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "b7aae7f9-83be-4d86-9cf4-9f712f73b5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a ver lo que he visto esta no es la que decía yo la que acaban que en ese dice el proceso el proceso derrotado de folder a pe folder como que no arranca vale este es el proceso que pasa los desarrolladores dejan sus cosas en carpeta e y automáticamente se pasa carpeta p si ha ido bien vale entonces si no salta suele ser porque el proceso que se encarga de ello que está aquí en p y m utilidades vale este rotado carpetas por lo que sea mejor se ha quedado pillado en teoría yo lo que he hecho ha sido darle a un restar al proceso que ya ha acabado al cliente le puede decir que ya ha acabado pero hay que ver es que pilla la planificación porque si ponen otro vamos a estar en la misma vale entonces el rollo es aquí no es que duro pues te vienes aquí haces un versión check out para poder manipular el workflow vale te vas a workflow ed y schedule es schedule aquí schedule y aquí viene la digamos cuando como ejecutarse entonces después de ponerle que empiece yo no sé por qué supone que esto normalmente debe estar siempre corriendo y si le das aquí que corra cada minuto debería bastar sabes para que ya se se pongan más vale sabe que para sabes que estaba puesto que no se ejecutaba o no estaba puesto bien pero es que no sé hay veces que se pierde la planificación ahora parece que sí que va a correr bueno habría que esto te vas aquí a la 9.02 si tiene su propia carpeta de utilidades rotarte folder se llama rotarte folder aquí vale que vas al lado no son rotados día el último esto es que ha corrido yo creo que si pongo resumen rotado de otro día pone todas así ahí pone todas vamos a ver ahora si mete una entrada sabes si hay 55 que no me ha puesto no me parece o hay 50 pues habría que ver aquí que escribe y que luego va a escribir 56 y así entonces ya vemos que vamos si quieres esto dejalo al usuario y le pues ya tu rotado ya tal vez hemos revisado y ya me dejo esto no decía y esto voy a echar lo dejo yo aquí abierto y reviso que ya va vale lo que te iba a decir es que las 9.24 del día de hoy se ve que si son rotados sí pero por eso he llegado yo aquí y le hecho aquí está entonces se ha ejecutado fuera de planificación en directamente lo he ejecutado para que fuera lo del esto te voy a pasar aquí el lo y sobre la otra petición de ayer comentado con tomás porque él ha estado más con el tema de jaz y que de hecho un ojo si no luego lo vemos los tres vale una cosa importante no o sea no te dejes no te dejes peticiones aquí corriendo porque quiere decir que a ver que no es culpa tuyo mucho que por ejemplo está estas que tienes aquí esta no es de que es y es pero esas son de cosas que que había que mirar todavía de permisos de usuarios que justo me han dado ya vale pero a lo mejor aquí las puedes poner no me acuerdo cómo era creo que las puedes poner en pause o algo así para que no te corra esto aquí abajo que tiene un rollo de un no parece aquí no parece pero que luego pueden decirnos oye que ha pasado el tiempo de de respuesta entonces está igual o sea tenemos un tiempo para atenderla entonces a ver si este maestro tampoco es plan o sea que no digas la si no puede decir a tú como tu labor también aparte del buzón después de decir luego en nuestro chat interno y tenemos que revisar esta y nos mencionas a todos o lo que sea sabes y pero que no te las vayas dejando aquí sabes muerta porque luego a lo mejor como va corriendo el tiempo no os pueden decir algo o lo que sea sabes y está la puedes cerrar le dice lo que hemos hablado y luego eso pues no comentan más rollo interno nuestro si este maestro que no es de algo de Antonio pues yo que sé puede decir bueno pues luego vemos esta petición que llegó y para que no sea tú una de tus labores y hago si también se lo puedes transmitir pues es decir un poco de cien de coño aquí no se me queda nada cola o hay esto que tenemos pendiente lo que sea vale vale por nada si quieres cierre a esta y te he pasado aquí a ver si te lo he pasado para que veas lo derrotado donde es si quieres intenta también tú luego cuando eso acepto un check out ver todo esto que hemos visto que te acabo enseñar y si tienes dudas lo volvemos a ver porque hay varios de estos que están todos programados si los ves por aquí hacen distintas tareas vez que ponen el chévol si está funcionando mejor no tocarlo si si no si es sólo para que veas tú que mira pero yo creo que ya mira ya está corriendo cada minuto ves ya si vemos el lo ves ya va escribiendo cada minuto o sea que ya no quiere pasar a ser solucionado esto es para que pues no nos hagan tantas peticiones ya con este automáticamente pues van a hacer vale vale pues nada\n",
            "Result of transcription text saved to: /content/transcription.txt\n"
          ]
        }
      ],
      "source": [
        "# @title Transcribe with Whisper and save output to transcription.txt\n",
        "\n",
        "# Opciones para la transcripción utilizando el idioma detectado\n",
        "options = whisper.DecodingOptions(language=detected_language, without_timestamps=True, fp16=False)\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "result = model.transcribe(extracted_audio_path)\n",
        "print(result[\"text\"])\n",
        "\n",
        "# Guardar la transcripción en .txt\n",
        "result_text = result[\"text\"]\n",
        "file_path = '/content/transcription.txt'\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(result_text)\n",
        "\n",
        "print(f'Result of transcription text saved to: {file_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Summarise the transcript with the GPT-3.5 API and save the output to summary_transcription.txt\n",
        "\n",
        "def summarize_text(text):\n",
        "    client = OpenAI(\n",
        "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Tu tarea es generar un resumen completo y claro de reuniones de trabajo transcritas. El resumen debe incluir los puntos clave discutidos, las decisiones tomadas y cualquier acción o tarea asignada. Evita detalles innecesarios y enfócate en la esencia de la reunión. El resumen debe ser lo suficientemente informativo para alguien que no asistió a la reunión.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Por favor, resume la siguiente transcripción de la reunión: \" + text\n",
        "    }\n",
        "]\n",
        "    )\n",
        "\n",
        "    # Accede a la respuesta de la siguiente manera\n",
        "    resumen = chat_completion.choices[0].message.content.strip()\n",
        "    return resumen\n",
        "\n",
        "# Uso de la función de resumen\n",
        "result_text = result[\"text\"]\n",
        "summary = summarize_text(result_text)\n",
        "\n",
        "# El resumen hecho por gpt-3.5\n",
        "print(summary)\n",
        "\n",
        "# Guardar el resumen en un archivo .txt\n",
        "file_path = '/content/summary_transcription.txt'\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(summary)\n",
        "\n",
        "print(f'Summary text saved to: {file_path}')"
      ],
      "metadata": {
        "id": "kqc0yWXXRbNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "46f15b5d-e29b-41eb-bf2c-c4e36eb78857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La reunión tuvo lugar para discutir el proceso de rotación de carpetas en el trabajo de los desarrolladores. Se mencionó que a veces el proceso se queda pillado en la carpeta de utilidades y no se ejecuta correctamente. Se decidió reiniciar el proceso e informar al cliente una vez que haya finalizado. También se discutió el manejo de las peticiones pendientes y se acordó no dejarlas corriendo indefinidamente, sino ponerlas en pausa si es necesario. Se asignó la tarea de revisar las peticiones con el equipo y mencionar cualquier problema en nuestro chat interno. Además, se mencionó una solicitud relacionada con el tema de Jaz que se abordaría más adelante. Se compartió una carpeta con archivos sobre el proceso de rotación para que todos los participantes pudieran revisarlos y resolver cualquier duda.\n",
            "Summary text saved to: /content/summary_transcription.txt\n"
          ]
        }
      ]
    }
  ]
}